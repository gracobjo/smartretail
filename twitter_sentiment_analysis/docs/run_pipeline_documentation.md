# DocumentaciÃ³n TÃ©cnica - run_pipeline.py

## ğŸ“‹ DescripciÃ³n General

El archivo `run_pipeline.py` es el **orquestador principal** del sistema de anÃ¡lisis de sentimiento de Twitter. ActÃºa como punto de entrada Ãºnico que coordina todos los componentes del sistema y permite ejecutar diferentes modos de operaciÃ³n.

## ğŸ¯ PropÃ³sito

- **OrquestaciÃ³n**: Coordina todos los mÃ³dulos del sistema
- **ConfiguraciÃ³n**: Gestiona la configuraciÃ³n inicial del entorno
- **EjecuciÃ³n Modular**: Permite ejecutar componentes especÃ­ficos
- **Monitoreo**: Proporciona feedback en tiempo real del progreso

## ğŸ—ï¸ Arquitectura del Script

### Estructura Principal

```python
#!/usr/bin/env python3
"""
Script principal para ejecutar el Pipeline de AnÃ¡lisis de Sentimiento en Twitter.
"""

import os
import sys
import argparse
from pathlib import Path

# Agregar el directorio src al path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))
```

### Funciones Principales

#### 1. **setup_directories()**
```python
def setup_directories():
    """Crear directorios necesarios."""
    directories = [
        'data/raw',
        'data/processed', 
        'data/sample',
        'models/saved',
        'results/visualizations',
        'results/reports',
        'results/exports',
        'logs'
    ]
```

**PropÃ³sito**: Crea la estructura de directorios necesaria para el funcionamiento del sistema.

**Directorios Creados**:
- `data/raw`: Datos crudos de Twitter
- `data/processed`: Datos procesados y limpios
- `data/sample`: Datos de ejemplo para testing
- `models/saved`: Modelos entrenados
- `results/visualizations`: Visualizaciones generadas
- `results/reports`: Reportes de anÃ¡lisis
- `results/exports`: Exportaciones de datos
- `logs`: Archivos de log del sistema

#### 2. **generate_sample_data()**
```python
def generate_sample_data():
    """Generar datos de ejemplo si no existen."""
    try:
        from src.data.data_processor import TwitterDataProcessor
        
        if not os.path.exists('data/processed/sample_tweets.csv'):
            processor = TwitterDataProcessor()
            sample_df = processor.create_sample_data(n_tweets=10000)
            processor.save_processed_data(sample_df, 'data/processed/sample_tweets.csv')
```

**PropÃ³sito**: Genera datos de ejemplo para testing y demostraciÃ³n.

**CaracterÃ­sticas**:
- Verifica si ya existen datos de ejemplo
- Genera 10,000 tweets de ejemplo
- Incluye distribuciÃ³n de sentimientos realista
- Guarda en formato CSV para fÃ¡cil acceso

#### 3. **run_sentiment_analysis()**
```python
def run_sentiment_analysis():
    """Ejecutar anÃ¡lisis de sentimiento."""
    try:
        from src.data.data_processor import TwitterDataProcessor
        from src.models.sentiment_analyzer import SentimentAnalyzer
        
        # Cargar datos
        processor = TwitterDataProcessor()
        df = processor.load_processed_data('data/processed/sample_tweets.csv')
        
        # Analizar sentimiento
        analyzer = SentimentAnalyzer()
        results_df = analyzer.analyze_tweets(df)
```

**PropÃ³sito**: Ejecuta el anÃ¡lisis de sentimiento completo.

**Flujo de Procesamiento**:
1. **Carga de Datos**: Carga tweets procesados
2. **AnÃ¡lisis BERT**: Aplica modelo de sentimiento
3. **CÃ¡lculo de Confianza**: Calcula puntuaciÃ³n de confianza
4. **EstadÃ­sticas**: Genera mÃ©tricas de rendimiento
5. **Almacenamiento**: Guarda resultados procesados

#### 4. **run_spark_pipeline()**
```python
def run_spark_pipeline():
    """Ejecutar pipeline de PySpark."""
    try:
        from src.spark.spark_pipeline import SparkSentimentPipeline
        from src.models.sentiment_analyzer import SentimentAnalyzer
        
        # Inicializar pipeline
        pipeline = SparkSentimentPipeline()
        
        # Crear datos de ejemplo
        pipeline.create_sample_data(n_tweets=5000)
        
        # Cargar y procesar datos
        df = pipeline.load_data('data/raw/sample_tweets.parquet')
        processed_df = pipeline.preprocess_text(df)
        featured_df = pipeline.create_text_features(processed_df)
```

**PropÃ³sito**: Ejecuta el pipeline distribuido con PySpark.

**CaracterÃ­sticas**:
- **Procesamiento Distribuido**: Utiliza Spark para escalabilidad
- **Optimizaciones**: Particionamiento y caching automÃ¡tico
- **Streaming**: Soporte para procesamiento en tiempo real
- **Fault Tolerance**: Tolerancia a fallos distribuidos

#### 5. **run_dashboard()**
```python
def run_dashboard():
    """Ejecutar dashboard interactivo."""
    try:
        from src.visualization.dashboard import TwitterSentimentDashboard
        
        print("Iniciando Twitter Sentiment Analysis Dashboard...")
        print("URL: http://localhost:8051")
        
        dashboard = TwitterSentimentDashboard()
        dashboard.run(debug=True, port=8051)
```

**PropÃ³sito**: Inicia el dashboard interactivo web.

**CaracterÃ­sticas**:
- **Interfaz Web**: Dashboard accesible vÃ­a navegador
- **Visualizaciones Interactivas**: GrÃ¡ficos dinÃ¡micos
- **Filtros en Tiempo Real**: Filtrado dinÃ¡mico de datos
- **Streaming de Datos**: Actualizaciones automÃ¡ticas

#### 6. **run_streaming_analysis()**
```python
def run_streaming_analysis():
    """Ejecutar anÃ¡lisis de streaming."""
    try:
        from src.models.sentiment_analyzer import StreamingSentimentAnalyzer
        
        analyzer = StreamingSentimentAnalyzer()
        
        # Ejemplos de tweets para probar
        sample_tweets = [
            "I love this new product! It's amazing! ğŸ˜",
            "This is terrible, worst experience ever! ğŸ˜ ",
            "The weather is nice today, feeling good! â˜€ï¸"
        ]
```

**PropÃ³sito**: Ejecuta anÃ¡lisis de sentimiento en tiempo real.

**CaracterÃ­sticas**:
- **Procesamiento Inmediato**: AnÃ¡lisis instantÃ¡neo
- **MÃ©tricas de Rendimiento**: Tiempo de procesamiento
- **EstadÃ­sticas Acumulativas**: MÃ©tricas del stream
- **Ejemplos Interactivos**: DemostraciÃ³n con tweets de ejemplo

## âš™ï¸ ConfiguraciÃ³n de Argumentos

### Parser de Argumentos
```python
def main():
    parser = argparse.ArgumentParser(description='Twitter Sentiment Analysis Pipeline')
    parser.add_argument('--mode', type=str, default='all', 
                       choices=['data', 'sentiment', 'spark', 'dashboard', 'streaming', 'all'],
                       help='Modo de ejecuciÃ³n')
    parser.add_argument('--port', type=int, default=8051, help='Puerto del dashboard')
    parser.add_argument('--setup-only', action='store_true', help='Solo configurar directorios')
```

### Modos de EjecuciÃ³n

| Modo | DescripciÃ³n | Comando |
|------|-------------|---------|
| `data` | Solo generar datos de ejemplo | `--mode data` |
| `sentiment` | Solo anÃ¡lisis de sentimiento | `--mode sentiment` |
| `spark` | Solo pipeline PySpark | `--mode spark` |
| `dashboard` | Solo dashboard interactivo | `--mode dashboard` |
| `streaming` | Solo anÃ¡lisis de streaming | `--mode streaming` |
| `all` | Ejecutar todo el pipeline | `--mode all` |

### Opciones Adicionales

| OpciÃ³n | DescripciÃ³n | Uso |
|--------|-------------|-----|
| `--port` | Puerto del dashboard | `--port 8051` |
| `--setup-only` | Solo configuraciÃ³n | `--setup-only` |

## ğŸ”„ Flujo de EjecuciÃ³n

### Diagrama de Flujo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Inicio        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Setup Directoriesâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Parse Arguments â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Check Mode      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
    â”‚           â”‚
    â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data    â”‚ â”‚ Sentimentâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚           â”‚
     â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Spark   â”‚ â”‚ Dashboardâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚           â”‚
     â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Streamingâ”‚ â”‚  End    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚           â”‚
     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Success   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### LÃ³gica de Control

```python
if args.mode in ['data', 'all']:
    print("\n1. Generando datos de ejemplo...")
    success &= generate_sample_data()

if args.mode in ['sentiment', 'all']:
    print("\n2. Ejecutando anÃ¡lisis de sentimiento...")
    success &= run_sentiment_analysis()

if args.mode in ['spark', 'all']:
    print("\n3. Ejecutando pipeline de PySpark...")
    success &= run_spark_pipeline()

if args.mode in ['streaming', 'all']:
    print("\n4. Ejecutando anÃ¡lisis de streaming...")
    success &= run_streaming_analysis()

if args.mode in ['dashboard', 'all']:
    print("\n5. Iniciando dashboard...")
    success &= run_dashboard()
```

## ğŸ“Š Manejo de Errores

### Estructura de Try-Catch
```python
def run_sentiment_analysis():
    """Ejecutar anÃ¡lisis de sentimiento."""
    try:
        # CÃ³digo de anÃ¡lisis
        return True
    except Exception as e:
        print(f"Error en anÃ¡lisis de sentimiento: {e}")
        return False
```

### Tipos de Errores Manejados

1. **Import Errors**: Errores de importaciÃ³n de mÃ³dulos
2. **File Not Found**: Archivos de datos no encontrados
3. **Model Loading Errors**: Errores al cargar modelos BERT
4. **Spark Configuration Errors**: Errores de configuraciÃ³n Spark
5. **Dashboard Errors**: Errores del servidor web

### Logging y Feedback
```python
print("=" * 60)
print("TWITTER SENTIMENT ANALYSIS PIPELINE - SmartRetail")
print("=" * 60)

if success:
    print("\nâœ… Pipeline completado exitosamente!")
else:
    print("\nâŒ Pipeline completado con errores.")
```

## ğŸš€ Ejemplos de Uso

### 1. **EjecuciÃ³n Completa**
```bash
# Ejecutar todo el pipeline
python run_pipeline.py --mode all
```

**Salida Esperada**:
```
============================================================
TWITTER SENTIMENT ANALYSIS PIPELINE - SmartRetail
============================================================
Directorios creados correctamente!

1. Generando datos de ejemplo...
Generando datos de ejemplo...
Datos generados exitosamente!
- Tweets: 10000
- Sentiment distribution:
positive    4500
negative    2500
neutral     3000

2. Ejecutando anÃ¡lisis de sentimiento...
Ejecutando anÃ¡lisis de sentimiento...
Resultados del anÃ¡lisis:
Total tweets: 10000
DistribuciÃ³n de sentimientos:
positive    4500
negative    2500
neutral     3000

3. Ejecutando pipeline de PySpark...
Ejecutando pipeline de PySpark...
Pipeline de PySpark completado exitosamente!

4. Ejecutando anÃ¡lisis de streaming...
Iniciando anÃ¡lisis de streaming...
Analizando tweets de ejemplo:
Tweet 1: I love this new product! It's amazing! ğŸ˜
Sentiment: positive
Confidence: 0.892

5. Iniciando dashboard...
Iniciando Twitter Sentiment Analysis Dashboard...
URL: http://localhost:8051

âœ… Pipeline completado exitosamente!
```

### 2. **Solo Dashboard**
```bash
# Ejecutar solo el dashboard
python run_pipeline.py --mode dashboard --port 8051
```

### 3. **Solo AnÃ¡lisis de Sentimiento**
```bash
# Ejecutar solo anÃ¡lisis de sentimiento
python run_pipeline.py --mode sentiment
```

### 4. **Solo ConfiguraciÃ³n**
```bash
# Solo crear directorios
python run_pipeline.py --setup-only
```

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de Entorno
```bash
# Configurar variables de entorno
export PYTHONPATH="${PYTHONPATH}:/path/to/twitter_sentiment_analysis"
export SPARK_HOME="/path/to/spark"
export TWITTER_API_KEY="your_api_key"
```

### ConfiguraciÃ³n de Logging
```python
import logging

# Configurar logging detallado
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/pipeline.log'),
        logging.StreamHandler()
    ]
)
```

### ConfiguraciÃ³n de Rendimiento
```python
# Configuraciones de rendimiento
performance_config = {
    'batch_size': 32,
    'max_workers': 4,
    'memory_limit': '4GB',
    'timeout': 300
}
```

## ğŸ“ˆ MÃ©tricas y Monitoreo

### MÃ©tricas de Rendimiento
```python
# MÃ©tricas tÃ­picas del pipeline
pipeline_metrics = {
    'total_execution_time': 45.2,  # segundos
    'data_generation_time': 5.1,
    'sentiment_analysis_time': 12.3,
    'spark_pipeline_time': 18.7,
    'dashboard_startup_time': 3.2,
    'memory_usage_mb': 2048,
    'cpu_usage_percent': 65
}
```

### Logs de EjecuciÃ³n
```python
# Estructura de logs
log_structure = {
    'timestamp': '2024-01-15T10:30:00Z',
    'mode': 'all',
    'status': 'success',
    'execution_time': 45.2,
    'errors': [],
    'warnings': []
}
```

## ğŸ› Troubleshooting

### Problemas Comunes

#### 1. **Error de ImportaciÃ³n**
```bash
# Error: ModuleNotFoundError: No module named 'src'
# SoluciÃ³n: Verificar PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:/path/to/twitter_sentiment_analysis"
```

#### 2. **Error de Spark**
```bash
# Error: SparkSession not initialized
# SoluciÃ³n: Verificar SPARK_HOME
export SPARK_HOME="/path/to/spark"
```

#### 3. **Error de Puerto**
```bash
# Error: Port already in use
# SoluciÃ³n: Cambiar puerto
python run_pipeline.py --mode dashboard --port 8052
```

### Debugging
```bash
# Ejecutar con logging detallado
python run_pipeline.py --mode all --log-level DEBUG

# Ver logs en tiempo real
tail -f logs/pipeline.log
```

## ğŸ“š Referencias

### Dependencias Principales
- **argparse**: Parsing de argumentos de lÃ­nea de comandos
- **pathlib**: ManipulaciÃ³n de rutas de archivos
- **sys**: Funcionalidades del sistema
- **os**: Interfaz con el sistema operativo

### MÃ³dulos del Sistema
- **src.data.data_processor**: Procesamiento de datos
- **src.models.sentiment_analyzer**: AnÃ¡lisis de sentimiento
- **src.spark.spark_pipeline**: Pipeline de Spark
- **src.visualization.dashboard**: Dashboard interactivo

---

*DocumentaciÃ³n tÃ©cnica del orquestador principal - SmartRetail Twitter Sentiment Analysis System* 